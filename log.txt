2022-03-23 at 17:17:59 | WARNING | Device: cuda, n_gpu: 1
2022-03-23 at 17:17:59 | WARNING | Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s
2022-03-23 at 17:17:59 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-23 at 17:18:03 | INFO | Training/evaluation parameters %s
2022-03-23 at 17:18:03 | INFO | Info: loading val features using 0.33 secs
2022-03-23 at 17:18:03 | INFO | val Data Examples: 10402
2022-03-23 at 17:21:18 | INFO | Info: loading train features using 194.88 secs
2022-03-23 at 17:21:27 | INFO | train Data Examples: 634516
2022-03-23 at 17:21:27 | INFO | Linear Scheduler (61950.0) with Warm Up (0) Steps
2022-03-23 at 17:21:27 | INFO | ***************** Running training *****************
2022-03-23 at 17:21:27 | INFO | =================  training info  ==================
2022-03-23 at 17:21:27 | INFO | ㄴNum examples = 634516
2022-03-23 at 17:21:27 | INFO | ㄴNum Epochs = 25.0
2022-03-23 at 17:21:27 | INFO | ㄴInstantaneous batch size per GPU = 8
2022-03-23 at 17:21:27 | INFO | ㄴGradient Accumulation steps = 32
2022-03-23 at 17:21:27 | INFO | ㄴTotal train batch size (w. parallel, distributed & accumulation) = 256
2022-03-23 at 17:21:27 | INFO | ㄴTotal optimization steps = 61950.0
2022-03-23 at 17:21:27 | INFO | ====================================================
2022-03-23 at 17:21:31 | INFO | Epoch 0 | global_step 1/61950.0 (0.00%) | global_loss 2232.8918 | global_acc 0.0000% | lr 0.000050 | global_time 3.8196sec
2022-03-23 at 17:21:31 | INFO | ***** Running evaluation 1 *****
2022-03-23 at 17:21:31 | INFO |   Num examples = %d
2022-03-23 at 17:21:31 | INFO |   Batch size = %d
2022-03-23 at 17:21:51 | INFO | Eval Results:
2022-03-23 at 17:21:51 | INFO | Eval Score: 0.000
2022-03-23 at 17:21:51 | INFO | EVALERR: 0.0%
2022-03-23 at 17:21:51 | INFO | Eval Upper Bound: 0.000
2022-03-23 at 17:21:51 | INFO | Eva Time Cost: 19.507
2022-03-23 at 17:21:52 | INFO | Epoch 0 | global_step 2/61950.0 (0.00%) | global_loss 2219.0326 | global_acc 0.0000% | lr 0.000050 | global_time 1.7602sec
2022-03-23 at 17:21:52 | INFO | ***** Running evaluation 2 *****
2022-03-23 at 17:21:52 | INFO |   Num examples = %d
2022-03-23 at 17:21:52 | INFO |   Batch size = %d
2022-03-23 at 17:22:09 | INFO | Eval Results:
2022-03-23 at 17:22:09 | INFO | Eval Score: 0.000
2022-03-23 at 17:22:09 | INFO | EVALERR: 0.0%
2022-03-23 at 17:22:09 | INFO | Eval Upper Bound: 0.000
2022-03-23 at 17:22:09 | INFO | Eva Time Cost: 16.814
2022-03-23 at 17:22:11 | INFO | Epoch 0 | global_step 3/61950.0 (0.00%) | global_loss 2205.7592 | global_acc 0.0000% | lr 0.000050 | global_time 1.6612sec
2022-03-23 at 17:22:11 | INFO | ***** Running evaluation 3 *****
2022-03-23 at 17:22:11 | INFO |   Num examples = %d
2022-03-23 at 17:22:11 | INFO |   Batch size = %d
2022-03-23 at 17:22:28 | INFO | Eval Results:
2022-03-23 at 17:22:28 | INFO | Eval Score: 0.000
2022-03-23 at 17:22:28 | INFO | EVALERR: 0.0%
2022-03-23 at 17:22:28 | INFO | Eval Upper Bound: 0.000
2022-03-23 at 17:22:28 | INFO | Eva Time Cost: 16.767
2022-03-23 at 17:22:29 | INFO | Epoch 0 | global_step 4/61950.0 (0.01%) | global_loss 2192.0700 | global_acc 0.0000% | lr 0.000050 | global_time 1.6979sec
2022-03-23 at 17:22:29 | INFO | ***** Running evaluation 4 *****
2022-03-23 at 17:22:29 | INFO |   Num examples = %d
2022-03-23 at 17:22:29 | INFO |   Batch size = %d
2022-03-23 at 17:22:46 | INFO | Eval Results:
2022-03-23 at 17:22:46 | INFO | Eval Score: 0.000
2022-03-23 at 17:22:46 | INFO | EVALERR: 0.0%
2022-03-23 at 17:22:46 | INFO | Eval Upper Bound: 0.000
2022-03-23 at 17:22:46 | INFO | Eva Time Cost: 17.015
2022-03-23 at 17:22:48 | INFO | Epoch 0 | global_step 5/61950.0 (0.01%) | global_loss 2177.9779 | global_acc 0.0000% | lr 0.000050 | global_time 1.6930sec
2022-03-23 at 17:22:48 | INFO | ***** Running evaluation 5 *****
2022-03-23 at 17:22:48 | INFO |   Num examples = %d
2022-03-23 at 17:22:48 | INFO |   Batch size = %d
2022-03-23 at 17:23:05 | INFO | Eval Results:
2022-03-23 at 17:23:05 | INFO | Eval Score: 0.000
2022-03-23 at 17:23:05 | INFO | EVALERR: 0.0%
2022-03-23 at 17:23:05 | INFO | Eval Upper Bound: 0.000
2022-03-23 at 17:23:05 | INFO | Eva Time Cost: 17.275
2022-03-23 at 17:23:07 | INFO | Epoch 0 | global_step 6/61950.0 (0.01%) | global_loss 2164.3167 | global_acc 0.0000% | lr 0.000050 | global_time 1.8077sec
2022-03-23 at 17:23:07 | INFO | ***** Running evaluation 6 *****
2022-03-23 at 17:23:07 | INFO |   Num examples = %d
2022-03-23 at 17:23:07 | INFO |   Batch size = %d
2022-03-23 at 17:23:24 | INFO | Eval Results:
2022-03-23 at 17:23:24 | INFO | Eval Score: 0.000
2022-03-23 at 17:23:24 | INFO | EVALERR: 0.0%
2022-03-23 at 17:23:24 | INFO | Eval Upper Bound: 0.000
2022-03-23 at 17:23:24 | INFO | Eva Time Cost: 16.942
2022-03-23 at 17:23:26 | INFO | Epoch 0 | global_step 7/61950.0 (0.01%) | global_loss 2151.1316 | global_acc 0.0000% | lr 0.000050 | global_time 1.7399sec
2022-03-23 at 17:23:26 | INFO | ***** Running evaluation 7 *****
2022-03-23 at 17:23:26 | INFO |   Num examples = %d
2022-03-23 at 17:23:26 | INFO |   Batch size = %d
2022-03-24 at 17:02:37 | WARNING | Device: cuda, n_gpu: 1
2022-03-24 at 17:02:38 | WARNING | Current cuda device: 0
2022-03-24 at 17:02:41 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 17:02:48 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda'), do_eval=False, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=True, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_q_length=27, max_seq_length=30, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg='configs/wandb_cfg.json', warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-24 at 17:02:51 | INFO | Info: loading val features using 3.15 secs
2022-03-24 at 17:02:51 | INFO | val Data Examples: 10402
2022-03-24 at 17:06:07 | INFO | Info: loading train features using 195.04 secs
2022-03-24 at 17:06:13 | INFO | train Data Examples: 634516
2022-03-24 at 17:06:13 | INFO | Linear Scheduler (61950.0) with Warm Up (0) Steps
2022-03-24 at 17:06:13 | INFO | ***************** Running training *****************
2022-03-24 at 17:06:13 | INFO | =================  training info  ==================
2022-03-24 at 17:06:13 | INFO | ㄴNum examples = 634516
2022-03-24 at 17:06:13 | INFO | ㄴNum Epochs = 25.0
2022-03-24 at 17:06:13 | INFO | ㄴInstantaneous batch size per GPU = 8
2022-03-24 at 17:06:13 | INFO | ㄴGradient Accumulation steps = 32
2022-03-24 at 17:06:13 | INFO | ㄴTotal train batch size (w. parallel, distributed & accumulation) = 256
2022-03-24 at 17:06:13 | INFO | ㄴTotal optimization steps = 61950.0
2022-03-24 at 17:06:13 | INFO | ====================================================
2022-03-24 at 19:59:28 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 19:59:29 | WARNING | Current cuda device: 0
2022-03-24 at 19:59:29 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 20:00:19 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 20:00:19 | WARNING | Current cuda device: 0
2022-03-24 at 20:00:19 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 20:00:26 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=False, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=True, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_q_length=27, max_seq_length=30, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-24 at 20:00:29 | INFO | Info: loading val features using 3.04 secs
2022-03-24 at 20:00:29 | INFO | val Data Examples: 10402
2022-03-24 at 20:03:56 | INFO | Info: loading train features using 206.19 secs
2022-03-24 at 20:04:09 | INFO | train Data Examples: 634516
2022-03-24 at 20:04:09 | INFO | Linear Scheduler (61950.0) with Warm Up (0) Steps
2022-03-24 at 20:04:09 | INFO | ***************** Running training *****************
2022-03-24 at 20:04:09 | INFO | =================  training info  ==================
2022-03-24 at 20:04:09 | INFO | ㄴNum examples = 634516
2022-03-24 at 20:04:09 | INFO | ㄴNum Epochs = 25.0
2022-03-24 at 20:04:09 | INFO | ㄴInstantaneous batch size per GPU = 8
2022-03-24 at 20:04:09 | INFO | ㄴGradient Accumulation steps = 32
2022-03-24 at 20:04:09 | INFO | ㄴTotal train batch size (w. parallel, distributed & accumulation) = 256
2022-03-24 at 20:04:09 | INFO | ㄴTotal optimization steps = 61950.0
2022-03-24 at 20:04:09 | INFO | ====================================================
2022-03-24 at 20:23:44 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 20:23:44 | WARNING | Current cuda device: 0
2022-03-24 at 20:23:44 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 20:23:52 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=True, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=False, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_seq_length=30, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-24 at 20:23:56 | INFO | Info: loading val features using 3.86 secs
2022-03-24 at 20:23:56 | INFO | val Data Examples: 10402
2022-03-24 at 20:23:56 | INFO | Evaluate the following checkpoints: %s
2022-03-24 at 20:24:41 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 20:24:41 | WARNING | Current cuda device: 0
2022-03-24 at 20:24:41 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 20:24:46 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=True, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=False, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=4000, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_seq_length=128, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='pretrained_base/base/checkpoint-2000000', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=32, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-24 at 20:24:46 | INFO | Info: loading val features using 0.49 secs
2022-03-24 at 20:24:47 | INFO | val Data Examples: 10402
2022-03-24 at 20:24:47 | INFO | Evaluate the following checkpoints: %s
2022-03-24 at 20:24:50 | INFO | ***** Running evaluation  *****
2022-03-24 at 20:24:50 | INFO |   Num examples = 10402
2022-03-24 at 20:24:50 | INFO |   Batch size = 256
2022-03-24 at 20:34:35 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 20:34:35 | WARNING | Current cuda device: 0
2022-03-24 at 20:34:35 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 20:34:39 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=True, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=False, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_seq_length=30, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-24 at 20:34:40 | INFO | Info: loading val features using 0.41 secs
2022-03-24 at 20:34:40 | INFO | val Data Examples: 10402
2022-03-24 at 20:34:40 | INFO | Evaluate the following checkpoints: %s
2022-03-24 at 20:36:12 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 20:36:12 | WARNING | Current cuda device: 0
2022-03-24 at 20:36:12 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 20:36:18 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 20:36:18 | WARNING | Current cuda device: 0
2022-03-24 at 20:36:18 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 20:36:22 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=False, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=False, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=True, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_seq_length=128, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-24 at 20:36:23 | INFO | Info: loading val features using 0.39 secs
2022-03-24 at 20:36:23 | INFO | val Data Examples: 10402
2022-03-24 at 20:39:33 | INFO | Info: loading train features using 189.90 secs
2022-03-24 at 20:39:41 | INFO | train Data Examples: 634516
2022-03-24 at 20:39:41 | INFO | Linear Scheduler (61950.0) with Warm Up (0) Steps
2022-03-24 at 20:39:41 | INFO | ***************** Running training *****************
2022-03-24 at 20:39:41 | INFO | =================  training info  ==================
2022-03-24 at 20:39:41 | INFO | ㄴNum examples = 634516
2022-03-24 at 20:39:41 | INFO | ㄴNum Epochs = 25.0
2022-03-24 at 20:39:41 | INFO | ㄴInstantaneous batch size per GPU = 8
2022-03-24 at 20:39:41 | INFO | ㄴGradient Accumulation steps = 32
2022-03-24 at 20:39:41 | INFO | ㄴTotal train batch size (w. parallel, distributed & accumulation) = 256
2022-03-24 at 20:39:41 | INFO | ㄴTotal optimization steps = 61950.0
2022-03-24 at 20:39:41 | INFO | ====================================================
2022-03-24 at 20:41:40 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 20:41:40 | WARNING | Current cuda device: 0
2022-03-24 at 20:41:40 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 20:41:51 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=True, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=False, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_seq_length=30, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-24 at 20:41:55 | INFO | Info: loading val features using 3.68 secs
2022-03-24 at 20:41:55 | INFO | val Data Examples: 10402
2022-03-24 at 20:41:55 | INFO | Evaluate the following checkpoints: %s
2022-03-24 at 22:01:34 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 22:01:34 | WARNING | Current cuda device: 0
2022-03-24 at 22:01:34 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 22:01:42 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=False, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=True, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_q_length=27, max_seq_length=30, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-24 at 22:01:43 | INFO | Info: loading val features using 1.29 secs
2022-03-24 at 22:01:43 | INFO | val Data Examples: 10402
2022-03-24 at 22:02:41 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 22:02:41 | WARNING | Current cuda device: 0
2022-03-24 at 22:02:41 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 22:02:45 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=False, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=True, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_q_length=27, max_seq_length=30, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-24 at 22:02:45 | INFO | Info: loading val features using 0.37 secs
2022-03-24 at 22:02:45 | INFO | val Data Examples: 10402
2022-03-24 at 22:05:41 | INFO | Info: loading train features using 175.21 secs
2022-03-24 at 22:05:48 | INFO | train Data Examples: 634516
2022-03-24 at 22:05:48 | INFO | Linear Scheduler (61950.0) with Warm Up (0) Steps
2022-03-24 at 22:05:48 | INFO | ***************** Running training *****************
2022-03-24 at 22:05:48 | INFO | =================  training info  ==================
2022-03-24 at 22:05:48 | INFO | ㄴNum examples = 634516
2022-03-24 at 22:05:48 | INFO | ㄴNum Epochs = 25.0
2022-03-24 at 22:05:48 | INFO | ㄴInstantaneous batch size per GPU = 8
2022-03-24 at 22:05:48 | INFO | ㄴGradient Accumulation steps = 32
2022-03-24 at 22:05:48 | INFO | ㄴTotal train batch size (w. parallel, distributed & accumulation) = 256
2022-03-24 at 22:05:48 | INFO | ㄴTotal optimization steps = 61950.0
2022-03-24 at 22:05:48 | INFO | ====================================================
2022-03-24 at 22:06:33 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-24 at 22:06:33 | WARNING | Current cuda device: 0
2022-03-24 at 22:06:33 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-24 at 22:06:40 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=False, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=True, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_q_length=27, max_seq_length=30, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-24 at 22:06:43 | INFO | Info: loading val features using 2.93 secs
2022-03-24 at 22:06:43 | INFO | val Data Examples: 10402
2022-03-24 at 22:09:37 | INFO | Info: loading train features using 174.41 secs
2022-03-24 at 22:09:45 | INFO | train Data Examples: 634516
2022-03-24 at 22:09:45 | INFO | Linear Scheduler (61950.0) with Warm Up (0) Steps
2022-03-24 at 22:09:45 | INFO | ***************** Running training *****************
2022-03-24 at 22:09:45 | INFO | =================  training info  ==================
2022-03-24 at 22:09:45 | INFO | ㄴNum examples = 634516
2022-03-24 at 22:09:45 | INFO | ㄴNum Epochs = 25.0
2022-03-24 at 22:09:45 | INFO | ㄴInstantaneous batch size per GPU = 8
2022-03-24 at 22:09:45 | INFO | ㄴGradient Accumulation steps = 32
2022-03-24 at 22:09:45 | INFO | ㄴTotal train batch size (w. parallel, distributed & accumulation) = 256
2022-03-24 at 22:09:45 | INFO | ㄴTotal optimization steps = 61950.0
2022-03-24 at 22:09:45 | INFO | ====================================================
2022-03-25 at 12:30:00 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-25 at 12:30:00 | WARNING | Current cuda device: 0
2022-03-25 at 12:30:00 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-25 at 12:30:07 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=False, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=True, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_q_length=27, max_seq_length=30, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-25 at 12:30:07 | INFO | Info: loading val features using 0.31 secs
2022-03-25 at 12:30:07 | INFO | val Data Examples: 10402
2022-03-25 at 12:30:32 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-25 at 12:30:32 | WARNING | Current cuda device: 0
2022-03-25 at 12:30:32 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-25 at 12:30:35 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=True, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=False, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hard_label=False, img_feat_dir=None, img_feat_format='pt', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=4000, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_seq_length=128, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='pretrained_base/base/checkpoint-2000000', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=32, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-25 at 12:30:36 | INFO | Info: loading val features using 0.27 secs
2022-03-25 at 12:30:36 | INFO | val Data Examples: 10402
2022-03-25 at 12:30:36 | INFO | Evaluate the following checkpoints: %s
2022-03-25 at 12:30:39 | INFO | ***** Running evaluation  *****
2022-03-25 at 12:30:39 | INFO |   Num examples = 10402
2022-03-25 at 12:30:39 | INFO |   Batch size = 256
2022-03-25 at 15:58:18 | WARNING | Device: cuda:0, n_gpu: 1
2022-03-25 at 15:58:18 | WARNING | Current cuda device: 0
2022-03-25 at 15:58:18 | INFO | Task Name: vqa_text, #Labels: 3129
2022-03-25 at 15:58:24 | INFO | Training/evaluation parameters Namespace(adam_epsilon=1e-08, add_imt=True, adjust_dp=False, adjust_loss=False, adjust_loss_epoch=-1, cache_dir='', classifier='linear', cls_hidden_scale=3, code_level='top', code_voc=512, config_name='', data_dir='data/vqa', data_label_type='mask', device=device(type='cuda', index=0), do_eval=False, do_lower_case=True, do_test=False, do_test_dev=False, do_test_dev_vqa2=False, do_test_vqa2=False, do_train=True, do_train_val=False, drop_out=0.3, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=32, hard_label=False, img_feat_dir=None, img_feat_format='lmdb', img_feature_dim=2054, img_feature_type='faster_r-cnn', label2ans_file=None, label_file='data/vqa/trainval_ans2label.pkl', learning_rate=5e-05, load_fast=False, local_rank=-1, logging_steps=1, loss_type='bce', max_grad_norm=1.0, max_img_seq_length=50, max_q_length=27, max_seq_length=30, max_steps=-1, model_name_or_path='pretrained_base/base/checkpoint-2000000', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=25.0, output_dir='results', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=256, per_gpu_train_batch_size=8, philly=False, save_after_epoch=-1, save_epoch=1, save_steps=-1, scheduler='linear', seed=88, server_ip='', server_port='', task_name='vqa_text', tokenizer_name='', txt_data_dir='data/vqa', use_vg=False, use_vg_dev=False, wandb_cfg=None, warmup_steps=0, weight_decay=0.05, workers=0)
2022-03-25 at 15:58:24 | INFO | Info: loading val features using 0.02 secs
2022-03-25 at 15:58:24 | INFO | val Data Examples: 10402
2022-03-25 at 15:58:24 | INFO | Info: loading train features using 0.07 secs
2022-03-25 at 15:58:30 | INFO | train Data Examples: 634516
2022-03-25 at 15:58:30 | INFO | Linear Scheduler (61950.0) with Warm Up (0) Steps
2022-03-25 at 15:58:30 | INFO | ***************** Running training *****************
2022-03-25 at 15:58:30 | INFO | =================  training info  ==================
2022-03-25 at 15:58:30 | INFO | ㄴNum examples = 634516
2022-03-25 at 15:58:30 | INFO | ㄴNum Epochs = 25.0
2022-03-25 at 15:58:30 | INFO | ㄴInstantaneous batch size per GPU = 8
2022-03-25 at 15:58:30 | INFO | ㄴGradient Accumulation steps = 32
2022-03-25 at 15:58:30 | INFO | ㄴTotal train batch size (w. parallel, distributed & accumulation) = 256
2022-03-25 at 15:58:30 | INFO | ㄴTotal optimization steps = 61950.0
2022-03-25 at 15:58:30 | INFO | ====================================================
